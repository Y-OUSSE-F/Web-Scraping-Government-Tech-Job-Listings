{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c39c9844",
   "metadata": {},
   "source": [
    "# USAJobs.gov Webscraping\n",
    "#### June 17th, 2024\n",
    "A step by step script to retrieve job listing data from the US federal government's official jobs site. Scrape conducted on 06/17/2024 for Pursuit.org by Youssef Agour for internal use purposes. \n",
    "\n",
    "Source site: https://www.usajobs.gov/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96a0cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (4.17.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: webdriver_manager in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (4.0.1)\n",
      "Requirement already satisfied: requests in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from webdriver_manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from webdriver_manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from webdriver_manager) (23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from requests->webdriver_manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from requests->webdriver_manager) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from requests->webdriver_manager) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/youssefagour/anaconda3/lib/python3.11/site-packages (from requests->webdriver_manager) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "# Library Install\n",
    "!pip install selenium \n",
    "!pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af57c5e0",
   "metadata": {},
   "source": [
    "### Step 1: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a4589ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium for webpage navigation\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Beautiful Soup for Website HTML Parsing\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Requests for calling website\n",
    "import urllib.request\n",
    "\n",
    "# Pandas, Numpy, and datetime for data manipulation & storage\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "# record when the data is crawled\n",
    "date_today = date.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d1bad4",
   "metadata": {},
   "source": [
    "### Step 2: Initialize Website for Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcd2da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Query url\n",
    "url = 'https://www.usajobs.gov/search/results/?g=0&g=1&g=2&g=3&g=4&g=5&g=6&g=7&g=8&g=9&g=10&j=0357&j=1560&j=2210&j=1550&l=&hp=public&p=6&smin=0&smax=85844&gs=true&k='\n",
    "\n",
    "# Jobs to crawl\n",
    "num_jobs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec0eee0",
   "metadata": {},
   "source": [
    "### Step 3: Investigate HTML structure and understand variables that can be scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4833a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty lists for data to be scraped\n",
    "jl = [] # Job Listing\n",
    "title = [] # Job Title\n",
    "agency = [] # Hiring Entity\n",
    "salary = [] # Salary Range Text\n",
    "grade = [] # Federal Grade Level\n",
    "timestamp = [] # When data is collected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df298052",
   "metadata": {},
   "source": [
    "### Step 4: Initialize Driver and collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd53226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the driver\n",
    "driver = webdriver.Chrome()\n",
    "driver.set_window_size(1120, 1300)\n",
    "driver.get(url)\n",
    "\n",
    "# Number of Jobs crawled\n",
    "jobcounts = 0\n",
    "\n",
    "# Initializing Scrape\n",
    "while num_jobs > jobcounts:\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    job_elements = soup.find_all('a', {'class': 'usajobs-search-result--core__title search-joa-link'})\n",
    "    \n",
    "    for i in range(len(job_elements)):\n",
    "        if num_jobs > jobcounts:\n",
    "            \n",
    "            s1 = job_elements[i]\n",
    "            \n",
    "            # Job Link\n",
    "            job_link = 'https://www.usajobs.gov/' + s1.get('href')\n",
    "            jl.append(job_link)\n",
    "            \n",
    "            # Go into specific job link\n",
    "            driver.get(job_link)\n",
    "            \n",
    "            # If job counts > 2 may need human clicks\n",
    "            if jobcounts > 2:\n",
    "                time.sleep(1)\n",
    "                \n",
    "            s_l2 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            \n",
    "            # job title\n",
    "            try:\n",
    "                title.append(s_l2.find('h1', {'class': \"usajobs-joa-banner__title\"}).text)\n",
    "            except Exception as e:\n",
    "                title.append('N/A')\n",
    "                print(f\"Failed to scrape job title: {e}\")\n",
    "            \n",
    "            # agency\n",
    "            try:\n",
    "                agency.append(s_l2.find('a', {'class': \"usajobs-joa-banner__agency usajobs-joa-banner--v1-3__agency\"}).text)\n",
    "            except Exception as e:\n",
    "                agency.append('N/A')\n",
    "                print(f\"Failed to scrape exam requirement: {e}\")\n",
    "            \n",
    "            try:\n",
    "                salary_widget_div = s_l2.find('p', {'class': 'usajobs-joa-summary__salary salary-text-normal'})\n",
    "    \n",
    "                if salary_widget_div:\n",
    "                    salary_text = salary_widget_div.get_text(strip=True)\n",
    "                    salary.append(salary_text)\n",
    "                else:\n",
    "                    salary.append('N/A')\n",
    "\n",
    "            except Exception as e:\n",
    "                salary.append('N/A')\n",
    "                print(f\"Failed to scrape salary: {e}\")\n",
    "            \n",
    "                   \n",
    "            # Grade\n",
    "            try:\n",
    "                grade.append(s_l2.find('p', {'class':'usajobs-joa-summary__grades'}).text)\n",
    "            except Exceptions as e:\n",
    "                grade.append('N/A')\n",
    "                print(f\"Failed to scrape number of open positions: {e}\")\n",
    "                \n",
    "            # timestamp\n",
    "            timestamp.append(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            \n",
    "            # Increment job count\n",
    "            jobcounts += 1\n",
    "            \n",
    "            time.sleep(1)\n",
    "            \n",
    "            \n",
    "        else: \n",
    "            break\n",
    "    \n",
    "    # filp page\n",
    "    # click to the next page\n",
    "    \n",
    "    driver.get(url)\n",
    "    \n",
    "    # wait for 2 seconds to click the button\n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        nextpage_path = '/html/body/section/section/div/main/div[5]/div[12]/ul/li[8]/a'\n",
    "        driver.find_element(By.XPATH,nextpage_path).click()\n",
    "        time.sleep(10)\n",
    "    except:\n",
    "        break \n",
    "        \n",
    "    # update main page url\n",
    "    url = driver.current_url\n",
    "    \n",
    "# Close the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07ed426",
   "metadata": {},
   "source": [
    "### Step 5: Pool Data into Dataframe format and ensure output is useable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad914b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble dataframe\n",
    "df = pd.DataFrame(list(zip(jl, title, salary, agency, grade)),\n",
    "                 columns = ['Job Link', 'Job Title', 'Salary', 'Agnecy', 'Pay & Qualification Grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d4f016c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d55b710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Link</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Agnecy</th>\n",
       "      <th>Pay &amp; Qualification Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>https://www.usajobs.gov//job/795837300</td>\n",
       "      <td>\\n                        ICAM Specialist \\n  ...</td>\n",
       "      <td>$68,405- $88,926 per year</td>\n",
       "      <td>\\n                        Federal Bureau of In...</td>\n",
       "      <td>GS 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>https://www.usajobs.gov//job/795878000</td>\n",
       "      <td>\\n                        Information Technolo...</td>\n",
       "      <td>$18.77- $21.77 per hour</td>\n",
       "      <td>\\n                        Air Force Global Str...</td>\n",
       "      <td>NF 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>https://www.usajobs.gov//job/795889800</td>\n",
       "      <td>\\n                        COMPUTER SCIENTIST \\...</td>\n",
       "      <td>$79,735- $103,658 per year</td>\n",
       "      <td>\\n                        United States Fleet ...</td>\n",
       "      <td>GG 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>https://www.usajobs.gov//job/795939400</td>\n",
       "      <td>\\n                        Information Technolo...</td>\n",
       "      <td>$82,764- $113,106 per year</td>\n",
       "      <td>\\n                        U.S. Army Cyber Comm...</td>\n",
       "      <td>GG 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>https://www.usajobs.gov//job/795971000</td>\n",
       "      <td>\\n                        IT Specialist INFOSE...</td>\n",
       "      <td>$66,732- $86,750 per year</td>\n",
       "      <td>\\n                        U.S. Pacific Fleet\\n...</td>\n",
       "      <td>GS 9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Job Link  \\\n",
       "140  https://www.usajobs.gov//job/795837300   \n",
       "141  https://www.usajobs.gov//job/795878000   \n",
       "142  https://www.usajobs.gov//job/795889800   \n",
       "143  https://www.usajobs.gov//job/795939400   \n",
       "144  https://www.usajobs.gov//job/795971000   \n",
       "\n",
       "                                             Job Title  \\\n",
       "140  \\n                        ICAM Specialist \\n  ...   \n",
       "141  \\n                        Information Technolo...   \n",
       "142  \\n                        COMPUTER SCIENTIST \\...   \n",
       "143  \\n                        Information Technolo...   \n",
       "144  \\n                        IT Specialist INFOSE...   \n",
       "\n",
       "                         Salary  \\\n",
       "140   $68,405- $88,926 per year   \n",
       "141     $18.77- $21.77 per hour   \n",
       "142  $79,735- $103,658 per year   \n",
       "143  $82,764- $113,106 per year   \n",
       "144   $66,732- $86,750 per year   \n",
       "\n",
       "                                                Agnecy  \\\n",
       "140  \\n                        Federal Bureau of In...   \n",
       "141  \\n                        Air Force Global Str...   \n",
       "142  \\n                        United States Fleet ...   \n",
       "143  \\n                        U.S. Army Cyber Comm...   \n",
       "144  \\n                        U.S. Pacific Fleet\\n...   \n",
       "\n",
       "    Pay & Qualification Grade  \n",
       "140                      GS 9  \n",
       "141                      NF 3  \n",
       "142                      GG 7  \n",
       "143                     GG 11  \n",
       "144                      GS 9  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a27ea5",
   "metadata": {},
   "source": [
    "### Step 6: Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e31a9ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df.to_csv('USAJOBS.govjobs_dataframe_final_0617.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
